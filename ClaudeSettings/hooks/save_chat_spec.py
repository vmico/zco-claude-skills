#!/usr/bin/env python3
"""
AI Code å¯¹è¯è‡ªåŠ¨ä¿å­˜è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
ä¿å­˜å®Œæ•´å¯¹è¯ + å·¥å…·è°ƒç”¨ + å‚è€ƒèµ„æº

Environment Variables:
- ZCO_CHAT_SAVE_SPEC: Must be "1" to enable this hook
- ZCO_CHAT_SAVE_DIR: Output directory (default: ${GIT_ROOT}/_.zco_hist)
"""
import json
import os
import sys
import re
import subprocess
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Set


def get_hist_dir(project_dir: Path = None) -> Path:
    """è·å–å†å²è®°å½•ç›®å½•"""
    hist_dir_name = os.environ.get('ZCO_CHAT_SAVE_DIR', None)
    git_root = get_git_root(project_dir)
    if not hist_dir_name:
        hist_dir = git_root / '_.zco_hist'
    else:
        hist_dir = os.path.abspath(os.path.join(str(git_root), hist_dir_name))
    hist_dir.mkdir(exist_ok=True)
    return hist_dir


def extract_keywords(text: str, max_keywords: int = 3) -> str:
    """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
    text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)
    words = text.split()

    stop_words = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª',
                  'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'is', 'are',
                  'è¯·', 'å¸®', 'æˆ‘è¦', 'èƒ½å¦', 'å¦‚ä½•', 'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å—', 'å‘¢'}

    keywords = []
    for word in words:
        word = word.strip()
        if len(word) >= 2 and word not in stop_words:
            if word not in keywords:
                keywords.append(word)
                if len(keywords) >= max_keywords:
                    break

    if not keywords:
        return "spec"

    return '_'.join(keywords[:max_keywords])


def get_git_root(project_dir: Path = None) -> Path:
    """è·å–å½“å‰ Git ä»“åº“æ ¹ç›®å½•"""
    try:
        # æ‰§è¡Œ git rev-parse --show-toplevel å‘½ä»¤
        if project_dir:
            result = subprocess.run(
                ['git', '-C', str(project_dir), 'rev-parse', '--show-toplevel'],
                capture_output=True, text=True, check=True
            )
        else:
            result = subprocess.run(
                ['git', 'rev-parse', '--show-toplevel'],
                capture_output=True, text=True, check=True
            )
        return Path(result.stdout.strip())
    except (subprocess.CalledProcessError, FileNotFoundError):
        return Path.cwd()


def format_message_content(msg_data: Any) -> str:
    """æ ¼å¼åŒ–æ¶ˆæ¯å†…å®¹ï¼ˆæ”¯æŒ AI Code æ ¼å¼ï¼‰"""
    # AI Code æ ¼å¼ï¼šå¤–å±‚ message å¯¹è±¡åŒ…å« role å’Œ content
    if isinstance(msg_data, dict) and 'message' in msg_data:
        msg_data = msg_data.get('message', {})

    # æå– content
    content = msg_data.get('content', msg_data) if isinstance(msg_data, dict) else msg_data
    if not content:
        return ''
    if isinstance(content, str):
        return content
    elif isinstance(content, list):
        parts = []
        for item in content:
            if isinstance(item, dict):
                if item.get('type') == 'text':
                    parts.append(item.get('text', ''))
                elif item.get('type') == 'tool_use':
                    tool_name = item.get('name', 'unknown')
                    parts.append(f"\n[ä½¿ç”¨å·¥å…·: {tool_name}]\n")
            elif isinstance(item, str):
                parts.append(item)
        return ''.join(parts)
    return str(content)


def extract_tool_calls(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æå–æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼ˆæ”¯æŒ AI Code æ ¼å¼ï¼‰"""
    tool_calls = []

    for msg in messages:
        # AI Code æ ¼å¼ï¼štype åœ¨å¤–å±‚
        msg_type = msg.get('type', '')
        if msg_type != 'assistant':
            continue

        # å†…å±‚ message å¯¹è±¡
        inner_msg = msg.get('message', {})
        content = inner_msg.get('content', [])
        if not isinstance(content, list):
            continue

        for item in content:
            if isinstance(item, dict) and item.get('type') == 'tool_use':
                tool_calls.append({
                    'name': item.get('name', 'unknown'),
                    'input': item.get('input', {}),
                    'id': item.get('id', '')
                })

    return tool_calls


def extract_tool_results(messages: List[Dict[str, Any]]) -> Dict[str, Any]:
    """æå–å·¥å…·è¿”å›ç»“æœï¼ˆæ”¯æŒ AI Code æ ¼å¼ï¼‰"""
    tool_results = {}

    for msg in messages:
        # AI Code æ ¼å¼ï¼šæ£€æŸ¥å¤–å±‚ type
        msg_type = msg.get('type', '')
        if msg_type != 'user':
            continue

        # æ£€æŸ¥æ˜¯å¦æœ‰ toolUseResult
        tool_result = msg.get('toolUseResult')
        if tool_result and isinstance(tool_result, dict):
            tool_id = tool_result.get('tool_use_id', '')
            result_content = tool_result.get('content', '')

            # è§£æç»“æœå†…å®¹
            if isinstance(result_content, list):
                text_parts = []
                for part in result_content:
                    if isinstance(part, dict) and part.get('type') == 'text':
                        text_parts.append(part.get('text', ''))
                result_content = '\n'.join(text_parts)

            tool_results[tool_id] = result_content

        # ä¹Ÿæ£€æŸ¥å†…å±‚ message ä¸­çš„ content
        inner_msg = msg.get('message', {})
        content = inner_msg.get('content', [])
        if not isinstance(content, list):
            continue

        for item in content:
            if isinstance(item, dict) and item.get('type') == 'tool_result':
                tool_id = item.get('tool_use_id', '')
                result_content = item.get('content', '')

                # è§£æç»“æœå†…å®¹
                if isinstance(result_content, list):
                    text_parts = []
                    for part in result_content:
                        if isinstance(part, dict) and part.get('type') == 'text':
                            text_parts.append(part.get('text', ''))
                    result_content = '\n'.join(text_parts)

                tool_results[tool_id] = result_content

    return tool_results


def extract_references(tool_calls: List[Dict], tool_results: Dict) -> Set[str]:
    """æå–å‚è€ƒèµ„æºï¼ˆURLsã€æ–‡ä»¶è·¯å¾„ç­‰ï¼‰"""
    references = set()

    # ä»å·¥å…·è°ƒç”¨ä¸­æå–
    for call in tool_calls:
        tool_name = call.get('name', '')
        tool_input = call.get('input', {})

        # WebFetch å·¥å…·
        if tool_name == 'WebFetch' or tool_name == 'WebSearch':
            url = tool_input.get('url', '')
            if url:
                references.add(f"ğŸŒ {url}")

        # Read å·¥å…·
        elif tool_name == 'Read':
            file_path = tool_input.get('file_path', '')
            if file_path:
                references.add(f"ğŸ“„ {file_path}")

        # Task å·¥å…·ï¼ˆAgent è°ƒç”¨ï¼‰
        elif tool_name == 'Task':
            agent_type = tool_input.get('subagent_type', '')
            if agent_type:
                references.add(f"ğŸ¤– Agent: {agent_type}")

    # ä»å·¥å…·ç»“æœä¸­æå– URLs
    for result in tool_results.values():
        if isinstance(result, str):
            # æå– http/https URLs
            urls = re.findall(r'https?://[^\s<>"{}|\\^`\[\]]+', result)
            for url in urls:
                references.add(f"ğŸŒ {url}")

    return references


def parse_transcript(transcript_path: str) -> List[Dict[str, Any]]:
    """è§£æ AI Code çš„ä¼šè¯æ–‡ä»¶ï¼ˆJSONL æ ¼å¼ï¼‰"""
    messages = []

    try:
        with open(transcript_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    msg = json.loads(line.strip())
                    # åªä¿ç•™ user å’Œ assistant ç±»å‹çš„æ¶ˆæ¯
                    if msg and msg.get('type') in ['user', 'assistant']:
                        messages.append(msg)
                except json.JSONDecodeError:
                    continue
    except Exception as e:
        print(f"Error reading transcript: {e}", file=sys.stderr)
        return []

    return messages


def generate_markdown(messages: List[Dict[str, Any]],
                      tool_calls: List[Dict],
                      references: Set[str],
                      session_id: str) -> str:
    """å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸º Markdown æ ¼å¼ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    if not messages:
        return "# å¯¹è¯è®°å½•\n\næ— å¯¹è¯å†…å®¹ã€‚\n"

    lines = []
    lines.append("# AI Code å¯¹è¯è®°å½•\n")
    lines.append(f"**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append(f"**ä¼šè¯ ID**: {session_id}\n")

    # æ·»åŠ å‚è€ƒèµ„æºéƒ¨åˆ†
    if references:
        lines.append("\n## ğŸ“š å‚è€ƒèµ„æº\n")
        for ref in sorted(references):
            lines.append(f"- {ref}\n")

    # æ·»åŠ å·¥å…·ä½¿ç”¨ç»Ÿè®¡
    if tool_calls:
        lines.append(f"\n**ä½¿ç”¨å·¥å…·**: {len(tool_calls)} æ¬¡\n")
        tool_counts = {}
        for call in tool_calls:
            name = call.get('name', 'unknown')
            tool_counts[name] = tool_counts.get(name, 0) + 1
        for name, count in sorted(tool_counts.items()):
            lines.append(f"  - {name}: {count} æ¬¡\n")

    lines.append("\n---\n")

    # å¯¹è¯å†…å®¹
    for idx, msg in enumerate(messages, 1):
        msg_type = msg.get('type', 'unknown')
        text = format_message_content(msg)
        if text.strip() == '':
            continue

        if msg_type == 'user':
            lines.append(f"\n## ğŸ‘¤ ç”¨æˆ·æé—® #{idx}\n")
            lines.append(f"{text}\n")
        elif msg_type == 'assistant':
            lines.append(f"\n## ğŸ¤– AiCode å›ç­” #{idx}\n")
            lines.append(f"{text}\n")

    lines.append("\n---\n")

    # é™„å½•ï¼šè¯¦ç»†çš„å·¥å…·è°ƒç”¨è®°å½•
    if tool_calls:
        lines.append("\n## ğŸ“‹ é™„å½•ï¼šå·¥å…·è°ƒç”¨è¯¦æƒ…\n")
        for idx, call in enumerate(tool_calls, 1):
            lines.append(f"\n### å·¥å…· {idx}: {call.get('name', 'unknown')}\n")
            lines.append("```json\n")
            lines.append(json.dumps(call, indent=2, ensure_ascii=False, default=str))
            lines.append("\n```\n")

    lines.append(f"\n---\n")
    lines.append(f"*è‡ªåŠ¨ç”Ÿæˆäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n")

    return '\n'.join(lines)


def save_resources(references: Set[str], output_dir: Path, base_filename: str):
    """ä¿å­˜å‚è€ƒèµ„æºåˆ—è¡¨åˆ°å•ç‹¬æ–‡ä»¶"""
    if not references:
        return

    resources_file = output_dir / f"{base_filename}_resources.txt"

    try:
        with open(resources_file, 'w', encoding='utf-8') as f:
            f.write(f"# å‚è€ƒèµ„æº\n")
            f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# å¯¹è¯æ–‡ä»¶: {base_filename}.md\n\n")

            for ref in sorted(references):
                f.write(f"{ref}\n")

        print(f"Resources saved to: {resources_file}", file=sys.stderr)
    except Exception as e:
        print(f"Error saving resources: {e}", file=sys.stderr)


def save_conversation(transcript_path: str, project_dir: str, session_id: str):
    """ä¿å­˜å¯¹è¯åˆ° Markdown æ–‡ä»¶ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    try:
        # è§£æä¼šè¯æ–‡ä»¶
        messages = parse_transcript(transcript_path)
        if not messages:
            print("No messages to save", file=sys.stderr)
            return

        # æå–å·¥å…·è°ƒç”¨å’Œç»“æœ
        tool_calls = extract_tool_calls(messages)
        tool_results = extract_tool_results(messages)
        references = extract_references(tool_calls, tool_results)

        # æå–ç¬¬ä¸€ä¸ªç”¨æˆ·æé—®ä½œä¸ºå…³é”®è¯æ¥æº
        first_user_msg = ""
        for msg in messages:
            if msg.get('type') == 'user':
                first_user_msg = format_message_content(msg)
                if first_user_msg:
                    break

        # æå–å…³é”®è¯
        keywords = extract_keywords(first_user_msg)

        # ç”Ÿæˆæ–‡ä»¶å: YYmmddHH_{å…³é”®è¯}
        timestamp = datetime.now().strftime('%y%m%d_%H%M%S')
        base_filename = f"AiCode_log_{timestamp}_{keywords}"
        filename = f"{base_filename}.md"

        # ä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„ç›®å½•ï¼Œé»˜è®¤ _.zco_hist
        hist_dir = get_hist_dir(project_dir)

        # ç”Ÿæˆ Markdown å†…å®¹
        markdown_content = generate_markdown(messages, tool_calls, references, session_id)

        # ä¿å­˜ä¸»æ–‡ä»¶
        output_file = hist_dir / filename
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        print(f"Conversation saved to: {output_file}", file=sys.stderr)

        # ä¿å­˜å‚è€ƒèµ„æºåˆ—è¡¨
        save_resources(references, hist_dir, base_filename)

    except Exception as e:
        print(f"Error saving conversation: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)


def main():
    """ä¸»å‡½æ•°"""
    try:
        # Check if this hook is enabled via environment variable
        if os.environ.get('ZCO_CHAT_SAVE_SPEC') != '1':
            # Silently exit if not enabled
            sys.exit(0)

        input_data = json.load(sys.stdin)
        hook_event = input_data.get('hook_event_name', '')

        if hook_event == 'Stop':
            transcript_path = input_data.get('transcript_path', '')
            cwd = input_data.get('cwd', '')
            session_id = input_data.get('session_id', 'unknown')

            if transcript_path and cwd:
                save_conversation(transcript_path, cwd, session_id)
            else:
                print(f"Missing required data: transcript_path={transcript_path}, cwd={cwd}", file=sys.stderr)

        sys.exit(0)

    except Exception as e:
        print(f"Hook error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc(file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
